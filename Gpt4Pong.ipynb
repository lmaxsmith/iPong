{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Define the custom dataset class\n",
    "class PaddleDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.tensor(self.data.iloc[idx, :8], dtype=torch.float32)\n",
    "        label = torch.tensor(self.data.iloc[idx, 8:].values.argmax(), dtype=torch.long)\n",
    "        return features, label\n",
    "\n",
    "# Define the neural network model\n",
    "class PaddleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PaddleClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(8, 32)\n",
    "        self.fc2 = nn.Linear(32, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Set the device to CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"TrainingDataReorg.tsv\", sep=\"\\t\")\n",
    "train_dataset = PaddleDataset(data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = PaddleClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "model_path = \"paddle_classifier.pth\"\n",
    "onnx_path = \"paddle_classifier.onnx\"\n",
    "\n",
    "# Load the model from disk if it exists\n",
    "if os.path.isfile(model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "    print(\"Model loaded from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6863\n",
      "Epoch [2/100], Loss: 0.5225\n",
      "Epoch [3/100], Loss: 0.3574\n",
      "Epoch [4/100], Loss: 0.4642\n",
      "Epoch [5/100], Loss: 0.5531\n",
      "Epoch [6/100], Loss: 0.5222\n",
      "Epoch [7/100], Loss: 0.6213\n",
      "Epoch [8/100], Loss: 0.5658\n",
      "Epoch [9/100], Loss: 0.5442\n",
      "Epoch [10/100], Loss: 0.6045\n",
      "Epoch [11/100], Loss: 0.6256\n",
      "Epoch [12/100], Loss: 0.7128\n",
      "Epoch [13/100], Loss: 0.4667\n",
      "Epoch [14/100], Loss: 0.5820\n",
      "Epoch [15/100], Loss: 0.5638\n",
      "Epoch [16/100], Loss: 0.7075\n",
      "Epoch [17/100], Loss: 0.6531\n",
      "Epoch [18/100], Loss: 0.5269\n",
      "Epoch [19/100], Loss: 0.2662\n",
      "Epoch [20/100], Loss: 0.3859\n",
      "Epoch [21/100], Loss: 0.5490\n",
      "Epoch [22/100], Loss: 0.5721\n",
      "Epoch [23/100], Loss: 0.5434\n",
      "Epoch [24/100], Loss: 0.4796\n",
      "Epoch [25/100], Loss: 0.3630\n",
      "Epoch [26/100], Loss: 0.3348\n",
      "Epoch [27/100], Loss: 0.4594\n",
      "Epoch [28/100], Loss: 0.4884\n",
      "Epoch [29/100], Loss: 0.5202\n",
      "Epoch [30/100], Loss: 0.6482\n",
      "Epoch [31/100], Loss: 0.4578\n",
      "Epoch [32/100], Loss: 0.5793\n",
      "Epoch [33/100], Loss: 0.6633\n",
      "Epoch [34/100], Loss: 0.6025\n",
      "Epoch [35/100], Loss: 0.5983\n",
      "Epoch [36/100], Loss: 0.4295\n",
      "Epoch [37/100], Loss: 0.6295\n",
      "Epoch [38/100], Loss: 0.4444\n",
      "Epoch [39/100], Loss: 0.4330\n",
      "Epoch [40/100], Loss: 0.2714\n",
      "Epoch [41/100], Loss: 0.3539\n",
      "Epoch [42/100], Loss: 0.6221\n",
      "Epoch [43/100], Loss: 0.3800\n",
      "Epoch [44/100], Loss: 0.5445\n",
      "Epoch [45/100], Loss: 0.5827\n",
      "Epoch [46/100], Loss: 0.5366\n",
      "Epoch [47/100], Loss: 0.3908\n",
      "Epoch [48/100], Loss: 0.4256\n",
      "Epoch [49/100], Loss: 0.5181\n",
      "Epoch [50/100], Loss: 0.5249\n",
      "Epoch [51/100], Loss: 0.5261\n",
      "Epoch [52/100], Loss: 0.6320\n",
      "Epoch [53/100], Loss: 0.6419\n",
      "Epoch [54/100], Loss: 0.4523\n",
      "Epoch [55/100], Loss: 0.3875\n",
      "Epoch [56/100], Loss: 0.5104\n",
      "Epoch [57/100], Loss: 0.3531\n",
      "Epoch [58/100], Loss: 0.6207\n",
      "Epoch [59/100], Loss: 0.5472\n",
      "Epoch [60/100], Loss: 0.7562\n",
      "Epoch [61/100], Loss: 0.4808\n",
      "Epoch [62/100], Loss: 0.3958\n",
      "Epoch [63/100], Loss: 0.6113\n",
      "Epoch [64/100], Loss: 0.3797\n",
      "Epoch [65/100], Loss: 0.4846\n",
      "Epoch [66/100], Loss: 0.4862\n",
      "Epoch [67/100], Loss: 0.5194\n",
      "Epoch [68/100], Loss: 0.5762\n",
      "Epoch [69/100], Loss: 0.6007\n",
      "Epoch [70/100], Loss: 0.3969\n",
      "Epoch [71/100], Loss: 0.5645\n",
      "Epoch [72/100], Loss: 0.4895\n",
      "Epoch [73/100], Loss: 0.4629\n",
      "Epoch [74/100], Loss: 0.6321\n",
      "Epoch [75/100], Loss: 0.4764\n",
      "Epoch [76/100], Loss: 0.6464\n",
      "Epoch [77/100], Loss: 0.3862\n",
      "Epoch [78/100], Loss: 0.5981\n",
      "Epoch [79/100], Loss: 0.5140\n",
      "Epoch [80/100], Loss: 0.4114\n",
      "Epoch [81/100], Loss: 0.4413\n",
      "Epoch [82/100], Loss: 0.3289\n",
      "Epoch [83/100], Loss: 0.6363\n",
      "Epoch [84/100], Loss: 0.4971\n",
      "Epoch [85/100], Loss: 0.5037\n",
      "Epoch [86/100], Loss: 0.3504\n",
      "Epoch [87/100], Loss: 0.3802\n",
      "Epoch [88/100], Loss: 0.7664\n",
      "Epoch [89/100], Loss: 0.5711\n",
      "Epoch [90/100], Loss: 0.7388\n",
      "Epoch [91/100], Loss: 0.4723\n",
      "Epoch [92/100], Loss: 0.6660\n",
      "Epoch [93/100], Loss: 0.3106\n",
      "Epoch [94/100], Loss: 0.3344\n",
      "Epoch [95/100], Loss: 0.5050\n",
      "Epoch [96/100], Loss: 0.3517\n",
      "Epoch [97/100], Loss: 0.4859\n",
      "Epoch [98/100], Loss: 0.3504\n",
      "Epoch [99/100], Loss: 0.5949\n",
      "Epoch [100/100], Loss: 0.5372\n",
      "Training complete\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # if (epoch + 1) % 10 == 0:\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to paddle_classifier.pth\n",
      "ONNX model saved to paddle_classifier.onnx\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model to disk\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Move the model back to CPU before exporting to ONNX\n",
    "model.to(\"cpu\")\n",
    "\n",
    "# Export the model to ONNX format\n",
    "dummy_input = Variable(torch.randn(1, 8))\n",
    "torch.onnx.export(model, dummy_input, onnx_path, verbose=True, input_names=[\"input\"], output_names=[\"output\"])\n",
    "\n",
    "# Check the ONNX model\n",
    "#onnx_model = torch.onnx.load(onnx_path)\n",
    "#onnx.checker.check_model(onnx_model)\n",
    "print(f\"ONNX model saved to {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test model with set inputs\n",
    "import numpy as np\n",
    "\n",
    "def predict(model, input_data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.tensor(input_data, dtype=torch.float32).to(device)\n",
    "        output = model(input_tensor)\n",
    "        probabilities = torch.softmax(output, dim=0)\n",
    "        predicted_class = torch.argmax(probabilities).item()\n",
    "    return probabilities, predicted_class\n",
    "\n",
    "# Example input data\n",
    "input_data = [2.02, 28.22204, 0.4549797, 0, -0.377058, -0.2713, -0.4834, -3.15]  # Replace this with your own input data\n",
    "probabilities, predicted_class = predict(model, input_data)\n",
    "\n",
    "# Map the predicted_class index to the corresponding label\n",
    "class_labels = ['MyPaddleIsRight', 'MyPaddleIsLeft', 'MyPaddleIsStill']\n",
    "predicted_label = class_labels[predicted_class]\n",
    "\n",
    "print(f\"Probabilities: {probabilities.cpu().numpy()}\")\n",
    "print(f\"Predicted class index: {predicted_class}\")\n",
    "print(f\"Predicted class label: {predicted_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
